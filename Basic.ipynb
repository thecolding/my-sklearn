{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac0ed38b8c6a201",
   "metadata": {},
   "source": [
    "# **数据预处理类**：DataPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242cfe9-5159-4b9e-98f3-7404a689dbc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T05:26:01.023076Z",
     "start_time": "2024-11-09T05:26:01.021214Z"
    },
    "collapsed": true
   },
   "source": [
    "## **简介**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c70ed1-1eeb-4e0b-aa35-b9d13aad05a4",
   "metadata": {},
   "source": [
    "#### 数据预处理是机器学习流程中的核心步骤，旨在优化数据的质量和格式，进而提高模型的表现和稳定性。DataPreprocessor 类提供了一系列常用的数据预处理工具，包括数据标准化、归一化、处理缺失值、类别编码、数据集划分，以及应对类别不平衡的采样方法。接下来将详细介绍每个方法的用途和实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb7641-7122-422b-a223-3a2a8fa562cb",
   "metadata": {},
   "source": [
    "## **代码概述**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e48e4-2411-4266-a3e4-e8fa192952bb",
   "metadata": {},
   "source": [
    "### **导入必要的库**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaeed15-2443-4d4d-8b77-699118fff011",
   "metadata": {},
   "source": [
    "#### 首先，导入数据预处理所需的库："
   ]
  },
  {
   "cell_type": "code",
   "id": "cb3c8b79-044c-438d-96cf-1cba02520357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T08:37:52.188115Z",
     "start_time": "2024-12-07T08:37:51.837007Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "4f480d5c-0318-40ec-87dd-d2e2245e9ea7",
   "metadata": {},
   "source": [
    "### **定义 DataPreprocessor 类**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f3853b-8ab7-4008-8799-ec4aafb3dda1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:49:36.114775Z",
     "start_time": "2024-11-09T08:49:36.107486Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.means = None\n",
    "        self.stds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e85a5a-1e28-4788-8130-8af097aa17eb",
   "metadata": {},
   "source": [
    "#### __init__ 方法初始化 self.means 和 self.stds，用于存储数据的均值和标准差，以便在标准化数据时进行计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eabcff-1ac0-4843-92c1-d9f4ef3c8d6b",
   "metadata": {},
   "source": [
    "### **1.标准化方法：standardize**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c3476-a576-4997-b932-2f93bd6b4b9b",
   "metadata": {},
   "source": [
    "#### **方法介绍**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6cb15-c598-4ea5-964f-bfd98fc5a06e",
   "metadata": {},
   "source": [
    "#### standardize 方法用于将数据标准化。标准化会将每个特征的均值调整为 0，标准差调整为 1。这在特征值范围差异较大的数据集上非常有用，可以防止某个特征主导模型的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad03dd5-7050-4f7b-aa94-d535f9e9c8b5",
   "metadata": {},
   "source": [
    "#### **方法实现**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f51232a-cdef-4ba9-b526-2f349e48916e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:49:36.132971Z",
     "start_time": "2024-11-09T08:49:36.118816Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardize(self, X):\n",
    "    self.means = np.mean(X, axis=0)\n",
    "    self.stds = np.std(X, axis=0)\n",
    "    return (X - self.means) / self.stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5df1c-864d-4550-815a-439d51b65364",
   "metadata": {},
   "source": [
    "* **输入**：X（NumPy 数组格式的数据）\n",
    "* **输出**：标准化后的数据"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **为什么使用标准化？**"
   ],
   "id": "8b4a22df5d8b2c34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 标准化对许多机器学习算法（如梯度下降法、SVM 和 KNN）非常重要，它可以加快模型收敛速度并提高模型性能。"
   ],
   "id": "bd11b99b84927da8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **2.最小-最大缩放方法：min_max_scaling**\n"
   ],
   "id": "4ed365c33f94b274"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **方法介绍**"
   ],
   "id": "84b1b2e9844c0197"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### min_max_scaling 方法将数据缩放到 [0, 1] 范围内，适合于需要归一化的数据集，如决策树、K-means 和神经网络。归一化可以让所有特征位于相同的范围内，消除特征之间的尺度差异。"
   ],
   "id": "48bd5faad590f867"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **方法实现**"
   ],
   "id": "dbf4328847096e27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def min_max_scaling(self, X):\n",
    "    return (X - np.min(X, axis=0)) / (np.max(X, axis=0) - np.min(X, axis=0))"
   ],
   "id": "36c1eb0f67a97463"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：X（数据集）\n",
    "* **输出**：归一化后的数据"
   ],
   "id": "2c0539e895e17992"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **使用场景**\n",
    "* **推荐系统**：归一化特征可以防止具有大范围值的特征对模型产生不良影响。\n",
    "* **图像处理**：将像素值缩放到 [0, 1]，提高模型的学习效率。"
   ],
   "id": "9512957741ac6e3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **3.处理缺失值方法：handle_missing_values**"
   ],
   "id": "fa84b7a794f1fbe2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **方法介绍**\n",
    "#### handle_missing_values 方法用于处理数据集中的缺失值。该方法支持两种策略：\n",
    "* **均值填充**：用每个特征的均值填充缺失值，适合大多数情况下的缺失值处理。\n",
    "* **删除样本**：删除包含缺失值的样本，适合缺失值较少或无法填充的情况。"
   ],
   "id": "df57e18c8250d475"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **方法实现**"
   ],
   "id": "91a9d72477e05c38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def handle_missing_values(self, X, strategy='mean'):\n",
    "    if strategy == 'mean':\n",
    "        for i in range(X.shape[1]):\n",
    "            col_mean = np.nanmean(X[:, i])\n",
    "            X[np.isnan(X[:, i]), i] = col_mean\n",
    "    elif strategy == 'drop':\n",
    "        X = X[~np.isnan(X).any(axis=1)]\n",
    "    return X"
   ],
   "id": "28683831ca5fdcb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：X（数据集），strategy（处理策略，默认为 mean）\n",
    "* **输出**：缺失值处理后的数据"
   ],
   "id": "447b1f067ab82593"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输出**：使用均值填充的缺失值数据。"
   ],
   "id": "26b42a7d2d85e00e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **使用策略**\n",
    "* **均值填充**：适用于缺失值分布较少且数据分布较均匀的情况。\n",
    "* **删除样本**：适用于缺失值较多或数据集本身样本量足够大的情况。"
   ],
   "id": "4899c0b389d382d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **4.编码类别特征方法：encode_categorical**"
   ],
   "id": "df794221e2aa2ad1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **方法介绍**\n",
    "#### encode_categorical 方法将类别特征转换为数值数据，使用 one-hot 编码方法。这对于无法直接输入模型的类别特征（如文本标签）非常重要。"
   ],
   "id": "947e072724fbdbac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **方法实现**"
   ],
   "id": "76064460fdbc0e89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def encode_categorical(self, X, categorical_features):\n",
    "    for feature in categorical_features:\n",
    "        unique_vals = np.unique(X[:, feature])\n",
    "        for val in unique_vals:\n",
    "            X = np.hstack((X, (X[:, feature] == val).astype(int).reshape(-1, 1)))\n",
    "        X = np.delete(X, feature, axis=1)\n",
    "    return X"
   ],
   "id": "f8678f4219e46a16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：X（数据集），categorical_features（类别特征索引列表）\n",
    "* **输出**：编码后的数据"
   ],
   "id": "43803f803eef831c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输出**：每个类别特征都被转换为一个独立的数值特征。"
   ],
   "id": "9024e6836a825ce6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **适用场景**\n",
    "* **文本分类**：将类别型文本标签转换为数值，以便输入到机器学习模型中。\n",
    "* **推荐系统**：将用户或物品的类别特征编码为模型可理解的格式。"
   ],
   "id": "7c53f31efc4032dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **5.训练-测试集划分方法：train_test_split**"
   ],
   "id": "b863f935a1c442b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **方法介绍**\n",
    "#### train_test_split 方法用于将数据集划分为训练集和测试集，以便评估模型的性能。通过控制 test_size 参数，可以调整测试集的大小。"
   ],
   "id": "e433e6c3a7483149"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **方法实现**"
   ],
   "id": "57caf4ca781f433d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_test_split(self, X, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    train_indices, test_indices = indices[:split_index], indices[split_index:]\n",
    "\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]"
   ],
   "id": "549df95b3b8c044"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：X（特征矩阵），y（标签向量），test_size（测试集比例），random_state（随机种子）\n",
    "* **输出**：训练集和测试集"
   ],
   "id": "5974ab4585ec9888"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **重要性**\n",
    "#### 划分训练集和测试集有助于评估模型的泛化能力，避免过拟合。"
   ],
   "id": "3ace44b82927e2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **6.数据不平衡处理方法**"
   ],
   "id": "1ed2829d6d505b4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **上采样方法**：oversample\n",
    "#### 此方法用于增加少数类样本数量，使所有类别的样本数量相等，从而缓解类别不平衡问题。"
   ],
   "id": "d585b744da025a72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def oversample(self, X, y):\n",
    "    counter = Counter(y)\n",
    "    max_count = max(counter.values())\n",
    "    X_resampled = []\n",
    "    y_resampled = []\n",
    "    for class_label in counter:\n",
    "        X_class = X[y == class_label]\n",
    "        y_class = y[y == class_label]\n",
    "        n_samples = max_count - len(y_class)\n",
    "        X_resampled.append(X_class)\n",
    "        y_resampled.append(y_class)\n",
    "        for _ in range(n_samples):\n",
    "            idx = np.random.randint(0, len(X_class))\n",
    "            X_resampled.append(X_class[idx].reshape(1, -1))\n",
    "            y_resampled.append(class_label)\n",
    "    return np.vstack(X_resampled), np.concatenate(y_resampled)"
   ],
   "id": "ab0db27a6a10e498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **下采样方法**：undersample\n",
    "#### 此方法用于减少多数类样本数量，使所有类别的样本数量相等，从而缓解类别不平衡问题。"
   ],
   "id": "db979e8d0624f542"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def undersample(self, X, y):\n",
    "    counter = Counter(y)\n",
    "    min_count = min(counter.values())\n",
    "    X_resampled = []\n",
    "    y_resampled = []\n",
    "    for class_label in counter:\n",
    "        X_class = X[y == class_label]\n",
    "        y_class = y[y == class_label]\n",
    "        indices = np.random.choice(len(X_class), min_count, replace=False)\n",
    "        X_resampled.append(X_class[indices])\n",
    "        y_resampled.append(y_class[indices])\n",
    "    return np.vstack(X_resampled), np.concatenate(y_resampled)"
   ],
   "id": "fc2bf4442ce6ed38"
  },
  {
   "cell_type": "markdown",
   "id": "6f60ef16-a41a-48a9-9b90-19e735f5ed20",
   "metadata": {},
   "source": [
    "#### **使用场景**\n",
    "* **上采样**：适用于少数类样本不足且希望保留所有数据的信息时。\n",
    "* **下采样**：适用于多数类样本过多且希望简化数据集时。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d86b9-890a-4fcb-8464-5aa56a43c6e3",
   "metadata": {},
   "source": [
    "### **7.数据加载和保存方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab6e35-176e-4f8e-bea7-f6e5656d0e3c",
   "metadata": {},
   "source": [
    "#### **加载数据方法：load_data**\n",
    "#### 此方法从 CSV 文件中加载数据，并返回为 NumPy 数组格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d674ddaf-05cd-48c6-a5ae-aca7f22c3b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:49:36.920557Z",
     "start_time": "2024-11-09T08:49:36.917502Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(self, filepath):\n",
    "    return pd.read_csv(filepath).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee1dba-2605-40f1-bb0a-4a5286290cb9",
   "metadata": {},
   "source": [
    "* **输入**：文件路径 filepath\n",
    "* **输出**：数据集（NumPy 数组）"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **保存数据方法：save_data**\n",
    "#### 此方法将特征和目标数据保存到 CSV 文件中，便于后续使用。"
   ],
   "id": "8097b6a5ca738823"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_data(self, X, y, filepath):\n",
    "    df = pd.DataFrame(X)\n",
    "    df['target'] = y\n",
    "    df.to_csv(filepath, index=False)"
   ],
   "id": "215258b015d21fc6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：X（特征），y（目标标签），filepath（文件路径）\n",
    "* **输出**：保存的数据集"
   ],
   "id": "e952bbcfbc9ed34b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **使用示例**\n",
    "#### **示例一：Iris 数据集（鸢尾花数据集）**\n",
    "Iris 数据集是经典的分类任务数据集，包含150个样本，每个样本有4个特征，分为三个类别。"
   ],
   "id": "c1638ab2f2814d54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from DataPart.DataPreprocessor import DataPreprocessor\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_iris\n",
    "# 加载 Iris 数据集\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# 初始化 DataPreprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "# 处理缺失值\n",
    "X = preprocessor.handle_missing_values(X, strategy='mean')\n",
    "# 标准化特征\n",
    "X_standardized = preprocessor.standardize(X)\n",
    "# 分割训练集和测试集\n",
    "X_train, X_test, y_train, y_test = preprocessor.train_test_split(X_standardized, y, test_size=0.2, random_state=42)\n",
    "# 查看类别分布\n",
    "print(\"原始训练集类别分布:\", Counter(y_train))\n",
    "# 使用 SMOTE 进行过采样\n",
    "X_resampled, y_resampled = preprocessor.oversample(X_train, y_train)\n",
    "print(\"过采样后的训练集类别分布:\", Counter(y_resampled))"
   ],
   "id": "61430e068db9a2ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **示例二：Wine 数据集（葡萄酒数据集）**\n",
    "Wine 数据集用于分类任务，根据13个特征将葡萄酒分类为三个类别。"
   ],
   "id": "62f1f9e58da301dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from DataPart.DataPreprocessor import DataPreprocessor\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_wine\n",
    "# 加载 Wine 数据集\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "# 初始化 DataPreprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "# 处理缺失值\n",
    "X = preprocessor.handle_missing_values(X, strategy='mean')\n",
    "# 标准化特征\n",
    "X_standardized = preprocessor.standardize(X)\n",
    "# 分割训练集和测试集\n",
    "X_train, X_test, y_train, y_test = preprocessor.train_test_split(X_standardized, y, test_size=0.2, random_state=42)\n",
    "# 查看类别分布\n",
    "print(\"原始训练集类别分布:\", Counter(y_train))\n",
    "# 使用欠采样平衡类别\n",
    "X_resampled, y_resampled = preprocessor.undersample(X_train, y_train)\n",
    "print(\"欠采样后的训练集类别分布:\", Counter(y_resampled))"
   ],
   "id": "fb09507b2e8f2655"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **示例三：Breast Cancer 数据集（乳腺癌数据集）**\n",
    "Breast Cancer 数据集用于二分类任务，预测是否存在癌症，基于30个特征。"
   ],
   "id": "b0d1d1e1c6689b4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from DataPart.DataPreprocessor import DataPreprocessor\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# 加载乳腺癌数据集\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "# 初始化 DataPreprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "# 处理缺失值\n",
    "X = preprocessor.handle_missing_values(X, strategy='mean')\n",
    "# 标准化特征\n",
    "X_standardized = preprocessor.standardize(X)\n",
    "# 分割训练集和测试集\n",
    "X_train, X_test, y_train, y_test = preprocessor.train_test_split(X_standardized, y, test_size=0.2, random_state=42)\n",
    "# 查看类别分布\n",
    "print(\"原始训练集类别分布:\", Counter(y_train))\n",
    "# 使用 SMOTE 进行过采样\n",
    "X_resampled, y_resampled = preprocessor.oversample(X_train, y_train)\n",
    "print(\"过采样后的训练集类别分布:\", Counter(y_resampled))"
   ],
   "id": "c450d4ebd81ad541"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **总结**\n",
    "#### DataPreprocessor 类提供了一套全面的工具集，用于数据预处理和优化。这些方法包括标准化、缩放、处理缺失值、编码类别特征、数据划分和应对类别不平衡问题。通过这些工具，可以更高效地为机器学习模型准备数据，并提高模型的表现和稳定性。"
   ],
   "id": "8b505bdc2f6c7c16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___"
   ],
   "id": "b290310d3253f911"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **数据集加载类：** DatasetLoader\n",
    "## **概述**\n",
    "DatasetLoader 类是一个用于加载多种常见机器学习数据集的工具。该类封装了多个数据集的下载、解压和预处理功能，简化了数据集的获取和使用过程。支持的数据集包括波士顿房价、手写数字、鸢尾花、乳腺癌、新闻组、LFW人脸、糖尿病、Linnerrud、葡萄酒、奥利维蒂人脸、森林覆盖、RCV1、KDD Cup、加利福尼亚房屋、泰坦尼克号以及CIFAR-10等。"
   ],
   "id": "fb615a581253e18a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **功能描述**\n",
    "- **自动下载和解压：** 对于需要从网络下载并解压的数据集，DatasetLoader 提供了自动化处理。\n",
    "- **数据预处理：** 加载数据后，自动分离特征（X）和标签（y），并进行必要的编码和转换。\n",
    "- **统一接口：** 通过统一的 load 方法，根据数据集名称加载对应的数据，简化了数据集的调用方式。\n",
    "- **扩展性强：** 可以方便地添加新的数据集加载方法，满足不同项目的需求。"
   ],
   "id": "5c0711bc8d0ee782"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **类结构**\n",
    "### 类：DatasetLoader\n",
    "**属性**\n",
    "- datasets (dict): 存储支持的数据集名称与对应加载方法的映射。\n",
    "\n",
    "**方法**\n",
    "- __init__(self): 初始化 datasets 字典，映射数据集名称到加载方法。\n",
    "- load(self, dataset_name): 根据提供的数据集名称加载对应的数据集。\n",
    "- 各数据集加载方法（如 load_boston, load_digits, load_iris 等）：具体实现各个数据集的下载、解压和预处理。\n",
    "- _download_and_extract(self, url): 辅助方法，用于下载和解压缩文件。"
   ],
   "id": "e15dc7c83553aabc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **数据集详情**\n",
    "以下是 DatasetLoader 支持的主要数据集及其来源：\n",
    "1. **波士顿房价 (boston)**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data)\n",
    "- 描述: 包含波士顿地区房屋的各种特征及其价格。\n",
    "\n",
    "2. **手写数字 (digits)**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/00360/digits.csv)\n",
    "- 描述: 包含手写数字图像的特征和标签。\n",
    "\n",
    "3. **鸢尾花 (iris)**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)\n",
    "- 描述: 包含鸢尾花的四个特征及其种类。\n",
    "\n",
    "4. **乳腺癌 (breast_cancer)**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/data.csv)\n",
    "- 描述: 包含乳腺癌患者的诊断特征。\n",
    "\n",
    "5. **新闻组 (newsgroups)**\n",
    "- 来源: [20 Newsgroups](http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz)\n",
    "- 描述: 包含20个不同新闻组的文本数据。\n",
    "\n",
    "6. **LFW人脸 (lfw)**\n",
    "- 来源: [LFW 数据集](http://vis-www.cs.umass.edu/lfw/lfw.tgz)\n",
    "- 描述: 包含人脸图像，用于人脸识别任务。\n",
    "\n",
    "7. **糖尿病 (diabetes)**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/diabetes/diabetes.data)\n",
    "- 描述: 包含糖尿病患者的特征及分类标签。\n",
    "\n",
    "8. **Linnerrud**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/00448/Linnerrud.txt)\n",
    "- 描述: 包含Linnerrud数据集的特征和目标值。\n",
    "\n",
    "9. **葡萄酒 (wine)**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/wine.data)\n",
    "- 描述: 包含葡萄酒的化学成分及其质量评分。\n",
    "\n",
    "10. **奥利维蒂人脸 (olivetti)**\n",
    "- 来源: [Olivetti Faces](https://cs.nyu.edu/~roweis/data/olivettifaces.gif)\n",
    "- 描述: 包含奥利维蒂人脸图像，用于人脸识别。\n",
    "\n",
    "11. **森林覆盖 (forest_cover)**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/covtype)\n",
    "- 描述: 包含森林覆盖类型的地理和环境特征。\n",
    "\n",
    "12. **RCV1**\n",
    "- 来源: [RCV1 数据集](https://paperswithcode.com/dataset/rcv1)\n",
    "- 描述: 包含新闻文章的文本数据，用于多类别分类。\n",
    "\n",
    "13. **KDD Cup**\n",
    "- 来源: [KDD Cup 数据集](https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)\n",
    "- 描述: 包含网络入侵检测的数据。\n",
    "\n",
    "14. **加利福尼亚房屋 (california_housing)**\n",
    "- 来源: [UCI 机器学习库](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data)\n",
    "- 描述: 包含加利福尼亚地区房屋的特征及价格。\n",
    "\n",
    "15. **泰坦尼克号 (titanic)**\n",
    "- 来源: [Kaggle 泰坦尼克号数据集]()\n",
    "- 描述: 包含泰坦尼克号乘客的特征及生存标签。\n",
    "\n",
    "16. **CIFAR-10**\n",
    "- 来源: [CIFAR-10 数据集](https://tensorflow.google.cn/datasets/catalog/cifar10)\n",
    "- 描述: 包含10类物体的彩色图像数据，用于图像分类。"
   ],
   "id": "fdd1b3bae1552e32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **使用说明**"
   ],
   "id": "42f419e9612db0ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **示例代码**"
   ],
   "id": "686868d84e46eb8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from DataPart.DatasetLoader import DatasetLoader\n",
    "# 创建 DatasetLoader 实例\n",
    "loader = DatasetLoader()\n",
    "# 加载鸢尾花数据集\n",
    "X, y = loader.load('iris')\n",
    "# 查看数据维度\n",
    "print(f\"特征维度: {X.shape}\")\n",
    "print(f\"标签维度: {y.shape}\")"
   ],
   "id": "4d4351ce8ae5f6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 加载支持的数据集\n",
    "调用 load 方法并传入数据集名称（不区分大小写）："
   ],
   "id": "c9c0042d15d023bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X, y = loader.load('boston')  # 加载波士顿房价数据集\n",
    "X, y = loader.load('digits')  # 加载手写数字数据集\n",
    "# 以此类推"
   ],
   "id": "168266be8b204079"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "对于某些数据集（如 newsgroups, lfw, cifar10），返回值为 None 或处理后的数据："
   ],
   "id": "28f453457d49789e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = loader.load('newsgroups')  # 返回 None"
   ],
   "id": "4245bce18ac909a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **结论**\n",
    "DatasetLoader 类提供了一个统一且简便的接口，用于加载多种常见的机器学习数据集。通过封装下载、解压和预处理过程，极大地简化了数据集的使用流程。未来可以通过引入更多功能和优化现有方法，进一步提升其实用性和性能。"
   ],
   "id": "137d32c56405c4e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "id": "85ea260e640dc016"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **模型评估类**：ModelEvaluator"
   ],
   "id": "a24329ab5be90fdf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **简介**\n",
    "#### 在机器学习模型中，准确地评估模型的性能是非常重要的。ModelEvaluator 类为此提供了一个全面的工具集，包括计算多种评估指标、生成混淆矩阵、绘制混淆矩阵和 ROC 曲线等功能。接下来将详细介绍每个方法的用途、实现原理及其示例。"
   ],
   "id": "4e519620155dca12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **导入必要的库**\n",
    "#### 首先，从 dataset.ModelEvaluator 模块导入 ModelEvaluator 类，并导入 numpy 和 matplotlib 库："
   ],
   "id": "55e482c13cf6ab3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 导入 ModelEvaluator 类\n",
    "from Model.ModelEvaluator import ModelEvaluator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "d73e3bfeff34d06b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **创建 ModelEvaluator 实例**"
   ],
   "id": "890bae600cc172bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建 ModelEvaluator 实例\n",
    "evaluator = ModelEvaluator()"
   ],
   "id": "56b57e60af34e5c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **方法详解**"
   ],
   "id": "cd7fc82a218413c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **1. 准确率方法：accuracy**\n",
    "#### accuracy 方法计算模型预测的正确率，即正确预测的样本占总样本的比例。"
   ],
   "id": "77a1d09200f2c82b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def accuracy(self, y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)"
   ],
   "id": "a97b4e932a0de8af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：真实标签 y_true，预测标签 y_pred\n",
    "* **输出**：准确率（0 到 1 之间的值"
   ],
   "id": "486be9912fa02a43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **2.精确率方法：precision**\n",
    "#### precision 方法计算模型预测的精确率，即正确预测为正类的样本占所有被预测为正类样本的比例。"
   ],
   "id": "ceb9b63357d1915"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **实现代码**"
   ],
   "id": "7cb95a5cca6fc22d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def precision(self, y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    return tp / (tp + fp) if (tp + fp) > 0 else 0"
   ],
   "id": "85b54169a6f42d2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：真实标签 y_true，预测标签 y_pred\n",
    "* **输出**：精确率（0 到 1 之间的值）"
   ],
   "id": "91220c3cdf07a337"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **3.召回率方法：recall**\n",
    "#### recall 方法计算模型的召回率，即正确预测为正类的样本占所有真实为正类样本的比例。"
   ],
   "id": "c1b947a99e97c917"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **实现代码**"
   ],
   "id": "f2b547b1143a3472"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def recall(self, y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return tp / (tp + fn) if (tp + fn) > 0 else 0"
   ],
   "id": "d0b0bda35982af87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：真实标签 y_true，预测标签 y_pred\n",
    "* **输出**：召回率（0 到 1 之间的值）"
   ],
   "id": "3e44fd73e245f2a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **4. F1 分数方法：f1_score**\n",
    "#### f1_score 方法计算模型的 F1 分数，这是精确率和召回率的调和平均值，用于综合评价模型的性能。"
   ],
   "id": "fc28a9f7cdebda28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **实现代码**"
   ],
   "id": "cd3c37c03eaa6e4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def f1_score(self, y_true, y_pred):\n",
    "    precision = self.precision(y_true, y_pred)\n",
    "    recall = self.recall(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0"
   ],
   "id": "a08a8240e46ee3f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：真实标签 y_true，预测标签 y_pred\n",
    "* **输出**：F1 分数（0 到 1 之间的值）"
   ],
   "id": "32220d2a0547fd0a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **5.综合评估方法：evaluate**\n",
    "#### evaluate 方法返回所有主要评估指标，包括准确率、精确率、召回率和 F1 分数。"
   ],
   "id": "6a17d0cb311cd29b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **实现代码**"
   ],
   "id": "961f3b362d05cac3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(self, y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy': self.accuracy(y_true, y_pred),\n",
    "        'precision': self.precision(y_true, y_pred),\n",
    "        'recall': self.recall(y_true, y_pred),\n",
    "        'f1_score': self.f1_score(y_true, y_pred)\n",
    "    }"
   ],
   "id": "5c3a3b1f54b98477"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **6. 混淆矩阵方法：confusion_matrix**\n",
    "#### confusion_matrix 方法生成混淆矩阵，表示分类模型的性能。"
   ],
   "id": "d3c71aa6a81756e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **实现代码**"
   ],
   "id": "3ec149a6838c0c4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def confusion_matrix(self, y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    cm = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    for i in range(len(y_true)):\n",
    "        cm[int(y_true[i]), int(y_pred[i])] += 1\n",
    "    return cm"
   ],
   "id": "e6d097c284492683"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：真实标签 y_true，预测标签 y_pred\n",
    "* **输出**：混淆矩阵（二维数组）"
   ],
   "id": "7bdd6c7a72d0d306"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **7. 绘制混淆矩阵方法：plot_confusion_matrix**\n",
    "#### plot_confusion_matrix 方法绘制混淆矩阵的可视化图。"
   ],
   "id": "a1b0b35584bbc083"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **实现代码**"
   ],
   "id": "d3e7d17dd3b0dd8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_confusion_matrix(self, y_true, y_pred):\n",
    "    cm = self.confusion_matrix(y_true, y_pred)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(np.unique(y_true)))\n",
    "    plt.xticks(tick_marks, np.unique(y_true))\n",
    "    plt.yticks(tick_marks, np.unique(y_true))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ],
   "id": "39d8d598903c21c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **8. 绘制 ROC 曲线方法：plot_roc_curve**\n",
    "#### plot_roc_curve 方法绘制 ROC 曲线，用于评估二分类模型的性能。"
   ],
   "id": "ba0d1a4694f86cf6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **实现代码**"
   ],
   "id": "191a9eda301f124e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_roc_curve(self, y_true, y_scores):\n",
    "    fpr, tpr, _ = self.roc_curve(y_true, y_scores)\n",
    "    plt.plot(fpr, tpr, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ],
   "id": "7f5a5c366005a05d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **输入**：真实标签 y_true，预测分数 y_scores\n",
    "* **输出**：ROC 曲线图"
   ],
   "id": "7383d037d8002401"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **使用示例**\n",
    "### **示例 一：使用鸢尾花（Iris）数据集评估逻辑回归模型**"
   ],
   "id": "283a1f1456afa127"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from Model.ModelEvaluator import ModelEvaluator\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# 仅选择二分类问题（类别 0 和 1）\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# 训练逻辑回归模型\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_scores = model.predict_proba(X_test)[:, 1]\n",
    "# 创建 ModelEvaluator 实例\n",
    "evaluator = ModelEvaluator()\n",
    "# 评估模型\n",
    "metrics = evaluator.evaluate(y_test, y_pred)\n",
    "print(\"准确率:\", metrics['accuracy'])\n",
    "print(\"精确率:\", metrics['precision'])\n",
    "print(\"召回率:\", metrics['recall'])\n",
    "print(\"F1 分数:\", metrics['f1_score'])\n",
    "# 绘制混淆矩阵和ROC曲线\n",
    "evaluator.plot_confusion_matrix(y_test, y_pred)\n",
    "evaluator.plot_roc_curve(y_test, y_scores)"
   ],
   "id": "3d710b1e66c25f01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **示例二：使用乳腺癌（Breast Cancer）数据集评估支持向量机（SVM）模型**"
   ],
   "id": "be8a782d5a195f64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from Model.ModelEvaluator import ModelEvaluator\n",
    "# 加载乳腺癌数据集\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# 训练支持向量机模型\n",
    "model = SVC(probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "# 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_scores = model.predict_proba(X_test)[:, 1]\n",
    "# 创建 ModelEvaluator 实例\n",
    "evaluator = ModelEvaluator()\n",
    "# 评估模型\n",
    "metrics = evaluator.evaluate(y_test, y_pred)\n",
    "print(\"准确率:\", metrics['accuracy'])\n",
    "print(\"精确率:\", metrics['precision'])\n",
    "print(\"召回率:\", metrics['recall'])\n",
    "print(\"F1 分数:\", metrics['f1_score'])\n",
    "# 绘制混淆矩阵和ROC曲线\n",
    "evaluator.plot_confusion_matrix(y_test, y_pred)\n",
    "evaluator.plot_roc_curve(y_test, y_scores)"
   ],
   "id": "dc9671d92f352348"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **总结**\n",
    "#### ModelEvaluator 类提供了一整套工具，帮助您全面评估机器学习模型的性能。从基本的准确率到更复杂的 ROC 曲线分析，您可以获得丰富的信息以优化和改进模型。通过这个类，您可以轻松实现模型性能的多维度分析。"
   ],
   "id": "5aec7d2bda1e193f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "id": "939b37774d8f66df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **模型的保存与加载类**：ModelPersistence\n",
    "## **概述**\n",
    "ModelPersistence 类提供了简便的方法用于保存和加载机器学习模型。通过使用 joblib 库，该类能够高效地序列化（保存）和反序列化（加载）模型对象，确保模型在不同环境中的可移植性和可重用性。该类设计为静态方法，方便在无需实例化类的情况下直接调用其功能。\n",
    "## **功能描述**\n",
    "- **模型保存：** 将训练好的模型对象序列化并保存到指定的文件中，便于后续的模型部署和共享。\n",
    "- **模型加载：** 从指定文件中反序列化并加载已保存的模型，方便在不同项目或环境中复用模型。\n",
    "- **错误处理：** 在保存和加载过程中，捕捉并处理可能出现的异常，提供友好的错误提示，提升使用体验。"
   ],
   "id": "551629e6b306b833"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **类结构**\n",
    "### 类：ModelPersistence\n",
    "### **方法**\n",
    "- save_model(model, filename) (静态方法)\n",
    "    - **描述**：将给定的模型对象保存到指定的文件中。\n",
    "    - **参数：**\n",
    "        - model：要保存的机器学习模型对象。\n",
    "        - filename：保存模型的目标文件路径。\n",
    "    - **返回值：** 无返回值，成功保存后打印确认信息，失败时打印错误信息。\n",
    "- load_model(filename) (静态方法)\n",
    "    - **描述**：从指定的文件中加载已保存的模型对象。\n",
    "    - **参数：**\n",
    "        - filename：要加载的模型文件路径。\n",
    "    - **返回值：** 返回加载的模型对象，加载失败时返回 None 并打印错误信息。"
   ],
   "id": "933a35fdde4ad1a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **使用说明：**\n",
    "### **示例代码**"
   ],
   "id": "368910a76b5cc1e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from Model.ModelPersistence import ModelPersistence\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 加载示例数据\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# 训练模型\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# 保存模型\n",
    "ModelPersistence.save_model(model, 'random_forest_model.joblib')\n",
    "# 加载模型\n",
    "loaded_model = ModelPersistence.load_model('random_forest_model.joblib')\n",
    "# 使用加载的模型进行预测\n",
    "if loaded_model is not None:\n",
    "    predictions = loaded_model.predict(X_test)\n",
    "    print(f\"预测结果: {predictions}\")"
   ],
   "id": "8d28609974fba06d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 方法调用示例\n",
    "**保存模型**"
   ],
   "id": "e7b7fa5502a30757"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ModelPersistence.save_model(model, 'model_filename.joblib')"
   ],
   "id": "89759eabe51e5357"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "参数说明：\n",
    "- model：需要保存的机器学习模型实例。\n",
    "- model_filename.joblib：目标保存文件的路径和名称。"
   ],
   "id": "3c0805cf5e40ea56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**加载模型**"
   ],
   "id": "ed9c0ba98a41d8de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loaded_model = ModelPersistence.load_model('model_filename.joblib')"
   ],
   "id": "4c4904e2b328589e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "参数说明：\n",
    "- model_filename.joblib：要加载的模型文件的路径和名称。\n",
    "\n",
    "返回值：\n",
    "- 成功加载时返回模型对象，失败时返回 None。"
   ],
   "id": "3a0159a7075f5a54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **结论**\n",
    "ModelPersistence 类为机器学习模型的保存和加载提供了简洁而高效的解决方案。通过封装 joblib 的功能，该类简化了模型持久化的流程，使得模型的复用和部署更加便捷。未来可以通过扩展其功能和增强其安全性，进一步提升其实用性和适用范围。"
   ],
   "id": "dd635c19e4b24cd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "7baed5233ef30cd9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
